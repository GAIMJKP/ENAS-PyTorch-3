{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitLayer(nn.Module):\n",
    "    \"\"\"The initial layer of the network: one convolution layer followed by one\n",
    "        batch normalization layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, trs=False, bias=False):\n",
    "        super(InitLayer, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2 # keep the same size\n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, \n",
    "                      out_channels, \n",
    "                      kernel_size = kernel_size, \n",
    "                      padding = padding, \n",
    "                      bias = bias), \n",
    "            nn.BatchNorm2d(out_channels, \n",
    "                           track_running_stats=trs))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.input_conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "conv = InitLayer(3, 6, 3)\n",
    "dumb_input = torch.zeros([1, 3, 224, 224], dtype=torch.float32)\n",
    "print(conv(dumb_input).shape)\n",
    "assert conv(dumb_input).shape == (1, 6, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedReduction(nn.Module):\n",
    "    \"\"\"Reduces the size of feature map (W and H) by a factor of 2\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, trs=False, bias=False):\n",
    "        super(FactorizedReduction, self).__init__()\n",
    "        assert out_channels % 2 == 0, \"Output channel number must be even :/\"\n",
    "        self.skip_path_1 = nn.Sequential(\n",
    "            nn.AvgPool2d(1, stride = 2), \n",
    "            nn.Conv2d(in_channels, \n",
    "                      out_channels // 2, \n",
    "                      kernel_size = 1, \n",
    "                      bias = bias))\n",
    "        \n",
    "        self.skip_path_2 = copy.deepcopy(self.skip_path_1)\n",
    "        self.padder = nn.ConstantPad2d((0, 1, 0, 1), 0)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, \n",
    "                                 track_running_stats=trs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input feature map with shape [N, C_in, H, W]\n",
    "            \n",
    "        Returns:\n",
    "            out: reudced feature map with shape [N, C_out, H // 2, W // 2]\n",
    "        \"\"\"\n",
    "        out_1 = self.skip_path_1(x) # skip path 1\n",
    "        out_2 = self.skip_path_2(self.padder(x)[:, :, 1:, 1:]) # skip path 2\n",
    "        assert out_1.shape == out_2.shape, \"Out1's shape {} and out2's shape {} does noe equal :/\".format(out_1.shape, out_2.shape)\n",
    "        out = torch.cat([out_1, out_2], dim=1)\n",
    "        \n",
    "        return self.bn(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "conv = FactorizedReduction(6, 12)\n",
    "dumb_input = torch.zeros([1, 6, 224, 224], dtype=torch.float32)\n",
    "print(conv(dumb_input).shape)\n",
    "assert conv(dumb_input).shape == (1, 12, 112, 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReluConvBN(nn.Module):\n",
    "    \"\"\"A combination of RELU -> CONV -> BATCH NORM.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, trs=False):\n",
    "        super(ReluConvBN, self).__init__()\n",
    "        \n",
    "        self.rcb = nn.Sequential(\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels = in_channels, \n",
    "                    out_channels = out_channels, \n",
    "                    kernel_size = 1),\n",
    "          nn.BatchNorm2d(out_channels, \n",
    "                         track_running_stats = trs))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.rcb(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "conv = ReluConvBN(6, 12)\n",
    "dumb_input = torch.zeros([1, 6, 224, 224], dtype=torch.float32)\n",
    "print(conv(dumb_input).shape)\n",
    "assert conv(dumb_input).shape == (1, 12, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBranch(nn.Module):\n",
    "    \"\"\"The identity branch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(IdentityBranch, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv(nn.Module):\n",
    "    \"\"\"Implement the depthwise-separable convolution cell.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=True):\n",
    "        super(SeparableConv, self).__init__()\n",
    "        \n",
    "        padding = (kernel_size - 1) // 2 # keep the size unchanged\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, \n",
    "                                   kernel_size=kernel_size, \n",
    "                                   padding=padding, \n",
    "                                   groups=in_channels, \n",
    "                                   bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, \n",
    "                                   kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [N, C_in, H, W]\n",
    "        \n",
    "        Return:\n",
    "            out: [N, C_out, H, W]\n",
    "        \"\"\"\n",
    "        out = self.pointwise(self.depthwise(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENASCell(nn.Module):\n",
    "    \"\"\"Implement one ENAS cell (or node), each cell can have 5 different operations:\n",
    "       avg_pool, max_pool, 3*3 conv, 5*5 conv, identity.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, node_id):\n",
    "        super(ENASCell, self).__init__()\n",
    "        \n",
    "        self.node_id = node_id\n",
    "        in_c, out_c = in_channels, out_channels\n",
    "        self.choices = nn.ModuleDict({\n",
    "                'conv3': nn.ModuleList([SeparableConv(in_c, out_c, 3)\n",
    "                                       for i in range(node_id)]), \n",
    "                'conv5': nn.ModuleList([SeparableConv(in_c, out_c, 5)\n",
    "                                       for i in range(node_id)]), \n",
    "                'avg_pool': nn.AvgPool2d(3, padding=1), \n",
    "                'max_pool': nn.MaxPool2d(3, padding=1), \n",
    "                'identity': IdentityBranch()\n",
    "        })\n",
    "        \n",
    "    def forward(self, x, prev_cell, op_id):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input from previous cell.\n",
    "            prev_cell: integer, the previous cell's ID.\n",
    "            op_id: integer, indicate which operation to use.\n",
    "        \"\"\"\n",
    "        assert 0 <= op_id <= 4, \"Operation ID out of range!\"\n",
    "        assert prev_cell < self.node_id, \"Previous cell ID out of range :/\"\n",
    "         \n",
    "        out = {\n",
    "          0: lambda x: self.choices['conv3'][prev_cell](x), \n",
    "          1: lambda x: self.choices['conv5'][prev_cell](x), \n",
    "          2: lambda x: self.choices['avg_pool'](x), \n",
    "          3: lambda x: self.choices['max_pool'](x), \n",
    "          4: lambda x: self.choices['identity'](x)\n",
    "        }[op_id](x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "cell = ENASCell(6, 12, 3)\n",
    "# for name, param in cell.named_parameters():\n",
    "#     print(\"Name: {}; Parameter size: {}\".format(name, param.size()))\n",
    "dumb_input = torch.zeros([1, 6, 224, 224], dtype=torch.float32)\n",
    "output = cell(dumb_input, 0, 1)\n",
    "print(output.shape)\n",
    "assert output.shape == (1, 12, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENASCellFixed(nn.Module):\n",
    "    \"\"\"Implement one ENAS cell (or node), each cell can have 5 different operations:\n",
    "       avg_pool, max_pool, 3*3 conv, 5*5 conv, identity.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, node_id):\n",
    "        super(ENASCellFixed, self).__init__()\n",
    "        \n",
    "        in_c, out_c = in_channels, out_channels\n",
    "        self.choices = nn.ModuleDict({\n",
    "                'conv3': SeparableConv(in_c, out_c, 3), \n",
    "                'conv5': SeparableConv(in_c, out_c, 5), \n",
    "                'avg_pool': nn.AvgPool2d(3, padding=1), \n",
    "                'max_pool': nn.MaxPool2d(3, padding=1), \n",
    "                'identity': IdentityBranch()\n",
    "        })\n",
    "        \n",
    "    def forward(self, x, prev_cell, op_id):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input from previous cell.\n",
    "            prev_cell: integer, the previous cell's ID.\n",
    "            op_id: integer, indicate which operation to use.\n",
    "        \"\"\"\n",
    "        assert 0 <= op_id <= 4, \"Operation ID out of range!\"\n",
    "        \n",
    "        out = {\n",
    "          0: lambda x: self.choices['conv3'](x), \n",
    "          1: lambda x: self.choices['conv5'](x), \n",
    "          2: lambda x: self.choices['avg_pool'](x), \n",
    "          3: lambda x: self.choices['max_pool'](x), \n",
    "          4: lambda x: self.choices['identity'](x)\n",
    "        }[op_id](x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "cell = ENASCellFixed(6, 12, 3)\n",
    "# for name, param in cell.named_parameters():\n",
    "#     print(\"Name: {}; Parameter size: {}\".format(name, param.size()))\n",
    "dumb_input = torch.zeros([1, 6, 224, 224], dtype=torch.float32)\n",
    "output = cell(dumb_input, 0, 1)\n",
    "print(output.shape)\n",
    "assert output.shape == (1, 12, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENASLayer(nn.Module):\n",
    "    \"\"\"Implement ENAS layer class, each layer composes B nodes: 2 input nodes and \n",
    "       (B - 2) operation nodes. Parameters in one ENAS layers are shared.\n",
    "       \n",
    "       One EnasLayer is equivalent to the Convolution or Reduction Cell in the\n",
    "       paper.\n",
    "       \n",
    "       The two input nodes have ID 0 and 1, the first operation node has ID 2 and \n",
    "       so on.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_num, out_channels, fixed=False):\n",
    "        super(ENASLayer, self).__init__()\n",
    "        self.node_num = node_num\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.frs = nn.ModuleList([FactorizedReduction(out_channels // 2, out_channels)\n",
    "                                    for i in range(2)])\n",
    "        self.final_rcb = ReluConvBN(out_channels * (node_num + 2), out_channels)\n",
    "        \n",
    "        # build cells (nodes), node_num does NOT include two input nodes\n",
    "        Cell = ENASCellFixed if fixed else ENASCell\n",
    "        self.nodes = nn.ModuleList()\n",
    "        for cell_id in range(2, node_num + 2):\n",
    "            self.nodes.append(Cell(out_channels, out_channels, cell_id))\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, arc):\n",
    "        \"\"\"Forward two inputs through one ENAS layer, the unused inputs are concatenated.\n",
    "        \n",
    "        Args:\n",
    "            inputs: (h[i], h[i-1]), \n",
    "            arc: list of integers, representing the architecture of the cell.\n",
    "        \"\"\"\n",
    "        assert len(arc) == self.node_num * 4, \"Oops, the length of arc is {}, which should be a multiple of 4 ({}).\".format(len(arc), self.node_num * 4)\n",
    "        assert len(inputs) == 2, \"Require exactly 2 inputs.\"\n",
    "        \n",
    "        node_inps = []\n",
    "        node_inps.extend(self._celibrate_size(inputs)) # assure two inputs have same shape\n",
    "        \n",
    "        for i in range(self.node_num):\n",
    "            # the first operation\n",
    "            x_id, x_op = arc[4 * i], arc[4 * i + 2]\n",
    "            x = node_inps[x_id]\n",
    "            x_out = self.nodes[i](x, x_id, x_op)\n",
    "            \n",
    "            # the second operation\n",
    "            y_id, y_op = arc[4 * i + 1], arc[4 * i + 3]\n",
    "            y = node_inps[y_id]\n",
    "            y_out = self.nodes[i](y, y_id, y_op)\n",
    "            \n",
    "            # add two op's outputs\n",
    "            out = x_out + y_out\n",
    "            node_inps.append(out)\n",
    "            \n",
    "        # concatenate all outputs and project\n",
    "        # NOTE: in the paper this is done for all unused nodes, here we make it sample\n",
    "        final_output = self.final_rcb(torch.cat(node_inps, dim=1))\n",
    "        assert final_output.shape == node_inps[0].shape, \"Oops, seems like the final output shape is wrong: {}. Should be equal to {}.\".format(final_output.shape, node_inps[0].shape)\n",
    "        \n",
    "        return final_output\n",
    "        \n",
    "        \n",
    "    def _celibrate_size(self, inputs):\n",
    "        \"\"\"Because of the reduction cell, the second input might have half WH size \n",
    "           and double depth size. This function is to make sure two inputs have the \n",
    "           same W and H, and the depth equals to out_channels.\n",
    "        \"\"\"\n",
    "        outs = []\n",
    "        for i, inp in enumerate(inputs):\n",
    "            if self._get_C(inp) != self.out_channels:\n",
    "                outs.append(self.frs[i](inp))\n",
    "            else:\n",
    "                outs.append(inp)\n",
    "                \n",
    "        assert outs[0].shape == outs[1].shape\n",
    "        return outs\n",
    "    \n",
    "    \n",
    "    def _get_C(self, x):\n",
    "        \"\"\"Get channel size of a given feature map.\n",
    "        \"\"\"\n",
    "        return x.shape[1]\n",
    "        \n",
    "        \n",
    "    def _get_HW(self, x):\n",
    "        \"\"\"Get H and W of a given feature map.\n",
    "        \"\"\"\n",
    "        return x.shape[-2], x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "layer = ENASLayer(2, 12, False)\n",
    "# for name, param in layer.named_parameters():\n",
    "#     print(\"Name: {}; Parameter size: {}\".format(name, param.size()))\n",
    "\n",
    "dumb_input1 = torch.zeros([1, 6, 64, 64], dtype=torch.float32)\n",
    "dumb_input2 = torch.zeros([1, 12, 32, 32], dtype=torch.float32)\n",
    "arc = [1, 1, 1, 4, 2, 0, 0, 0]\n",
    "output = layer([dumb_input1, dumb_input2], arc)\n",
    "\n",
    "print(output.shape)\n",
    "assert output.shape == (1, 12, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GlobalAvgPool(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxHeadLayer(nn.Module):\n",
    "    \"\"\"Auxiliary head for micro child training.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, side_length, trs=False, layer_sizes=[128, 768, 10]):\n",
    "        super(AuxHeadLayer, self).__init__()\n",
    "        assert len(layer_sizes) == 3, \"Should have exactly 3 layers in the auxiliary head.\"\n",
    "        \n",
    "        self.side_len = math.floor((side_length - 5) / 3 + 1)\n",
    "        self.aux = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(5, stride=3), \n",
    "            ReluConvBN(in_channels, layer_sizes[0]), \n",
    "            nn.Conv2d(layer_sizes[0], layer_sizes[1], self.side_len), \n",
    "            nn.ReLU(), \n",
    "        )\n",
    "        self.proj = nn.Linear(layer_sizes[1], layer_sizes[-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.aux(x)\n",
    "        logits = self.proj(torch.squeeze(torch.squeeze(out, dim=-1), dim=-1))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "layer = AuxHeadLayer(80, 8)\n",
    "# for name, param in layer.named_parameters():\n",
    "#     print(\"Name: {}; Parameter size: {}\".format(name, param.size()))\n",
    "\n",
    "dumb_input1 = torch.zeros([1, 80, 8, 8], dtype=torch.float32)\n",
    "output = layer(dumb_input1)\n",
    "\n",
    "print(output.shape)\n",
    "assert output.shape == (1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool(nn.Module):\n",
    "    \"\"\"Average all points of an image at each channel.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [N, C, H, W]\n",
    "        \"\"\"\n",
    "        return torch.mean(torch.mean(x, -1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80])\n"
     ]
    }
   ],
   "source": [
    "layer = GlobalAvgPool()\n",
    "\n",
    "dumb_input1 = torch.zeros([1, 80, 8, 8], dtype=torch.float32)\n",
    "output = layer(dumb_input1)\n",
    "\n",
    "print(output.shape)\n",
    "assert output.shape == (1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroChild(nn.Module):\n",
    "    \"\"\"A shared CNN graph\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(MicroChild, self).__init__()\n",
    "        self.config = config\n",
    "        self.init_layer = InitLayer(3, config.out_channels * 3, 3)\n",
    "        self.rcbs = nn.ModuleList([ReluConvBN(config.out_channels * 3, \n",
    "                                              config.out_channels) \n",
    "                                       for i in range(2)])\n",
    "        self.pool_layers_indices = self._specify_pool_layers()\n",
    "        self.layers = self._build_enas_layers()\n",
    "        if config.use_aux_heads:\n",
    "            self.aux, self.aux_head_indices = self._build_aux_heads()\n",
    "        self.proj = self._build_proj()\n",
    "        \n",
    "        \n",
    "    def _specify_pool_layers(self):\n",
    "        \"\"\"Specify which layers are pool layers (with reduction cell).\n",
    "        \"\"\"\n",
    "        pool_distance = self.config.num_layers // 3\n",
    "        return [pool_distance, pool_distance * 2 + 1]\n",
    "        \n",
    "        \n",
    "    def _build_enas_layers(self):\n",
    "        \"\"\"Build ENAS layers. In every pool layer, the channels are doubled.\"\"\"\n",
    "        node_num, out_c = self.config.node_num, self.config.out_channels\n",
    "        \n",
    "        layers = nn.ModuleList()\n",
    "        for i in range(config.num_layers):\n",
    "            if i in self.pool_layers_indices:\n",
    "                out_c = out_c * 2\n",
    "            layers.append(ENASLayer(node_num, out_c, self.config.fixed))\n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def _build_aux_heads(self):\n",
    "        \"\"\"Build auxiliary head for training.\"\"\"\n",
    "        pool_layer_num = len(self.pool_layers_indices)\n",
    "        channels = self.config.out_channels * pool_layer_num**2\n",
    "        side_length = self.config.image_size // pool_layer_num**2\n",
    "        \n",
    "        aux = AuxHeadLayer(channels, side_length)\n",
    "        aux_head_indices = [self.pool_layers_indices[-1] + 1]\n",
    "        \n",
    "        return aux, aux_head_indices\n",
    "\n",
    "        \n",
    "    def _build_proj(self):\n",
    "        \"\"\"The final projection layer for logits compution\"\"\"\n",
    "        channels = self.config.out_channels * len(self.pool_layers_indices)**2\n",
    "        proj = nn.Sequential(\n",
    "            nn.ReLU(), \n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(channels, self.config.class_num)\n",
    "        )\n",
    "        return proj\n",
    "        \n",
    "        \n",
    "    def forward(self, images, arcs):\n",
    "        \"\"\"Compute the logits given images.\n",
    "        \n",
    "        Args:\n",
    "            images: input images, [N, C_in, H, W], N is batch size.\n",
    "            arcs: a tuple of two lists that contain integers represents the architecture \n",
    "                of a normal cell and a reduce cell, four integers together in the list as\n",
    "                a node: (index_1, index_2, op_1, op_2).\n",
    "        \"\"\"\n",
    "        normal_arc, reduce_arc = arcs\n",
    "        x = self.init_layer(images)\n",
    "        \n",
    "        # NOTE: here the implementation is a litte different from Melody's\n",
    "        inputs = []\n",
    "        for i in range(len(self.rcbs)):\n",
    "            inputs.append(self.rcbs[i](x))\n",
    "        \n",
    "        # ENAS layers\n",
    "        aux_logits = None\n",
    "        for layer_id in range(self.config.num_layers):\n",
    "            x = self.layers[layer_id](inputs, normal_arc)\n",
    "            inputs = [inputs[-1], x]\n",
    "            \n",
    "            if self.config.use_aux_heads and layer_id in self.aux_head_indices \\\n",
    "                and self.training:\n",
    "                aux_logits = self.aux(x) # auxiliary head\n",
    "        \n",
    "        logits = self.proj(x)\n",
    "        \n",
    "        return logits, aux_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    out_channels = 20\n",
    "    num_layers = 15\n",
    "    node_num = 6\n",
    "    class_num = 10\n",
    "    image_size = 32\n",
    "    use_aux_heads = True\n",
    "    fixed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 10])\n",
      "Auxiliary logits shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "module = MicroChild(config)\n",
    "\n",
    "fake_iamge = torch.zeros([1, 3, 32, 32], dtype=torch.float32)\n",
    "arc = [1, 1, 1, 4, 2, 0, 0, 0] * 3\n",
    "logits, aux_logits = module(fake_iamge, (arc, arc))\n",
    "\n",
    "print(\"Logits shape: {}\".format(logits.shape))\n",
    "print(\"Auxiliary logits shape: {}\".format(aux_logits.shape))\n",
    "assert logits.shape == (1, 10)\n",
    "assert aux_logits.shape == (1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CELossWithAuxHead(nn.Module):\n",
    "    \"\"\"Module for computing cross entropy loss with possible auxiliary loss.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CELossWithAuxHead, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    def forward(self, logits, target, aux_logits=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: [batch_size, class_um]\n",
    "            target: [batch_size]\n",
    "            aux_logits: [batch_size, class_um]\n",
    "        \"\"\"\n",
    "        loss = self.criterion(logits, target)\n",
    "        \n",
    "        if aux_logits is not None:\n",
    "            aux_loss = self.criterion(aux_logits, target)\n",
    "            loss = loss + aux_loss * 0.4\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChildModel:\n",
    "    \"\"\"The class for child model training, validating and testing.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, device, write_summary=True):\n",
    "        \"\"\"Initialize model.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.logger = self.config.logger\n",
    "        \n",
    "        # find device\n",
    "        self.device = device\n",
    "\n",
    "        # build and initialize model\n",
    "        self.logger.info(\"- Building and initializing model...\")\n",
    "        self.model = self._build_model(config).to(device)\n",
    "        self._initialize_model(self.model)\n",
    "        \n",
    "        # create optimizer and criterion\n",
    "        self.logger.info(\"- Creating optimizer and criterion...\")\n",
    "        self.optimizer = self._get_optimizer(config, self.model)\n",
    "        self.criterion = self._get_criterion(config).to(device)\n",
    "\n",
    "        # create summary for tensorboard visualization\n",
    "        if write_summary:\n",
    "            self.writer = SummaryWriter(self.config.path_summary)\n",
    "        else:\n",
    "            self.writer = None        \n",
    "        \n",
    "        self.arcs = None # architecture for normal and reduction cell\n",
    "            \n",
    "        \n",
    "    def _build_model(self, config):\n",
    "        \"\"\"Build a model.\n",
    "        \"\"\"\n",
    "        return MicroChild(config)\n",
    "    \n",
    "        \n",
    "    def _initialize_model(self, model):\n",
    "        \"\"\"Model initialization.\n",
    "        \"\"\"\n",
    "        for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def _get_optimizer(self, config, model):\n",
    "        \"\"\"Get optimizer.\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(model.parameters(), lr=0, \n",
    "                                betas=(0.9, 0.98), eps=1e-9)\n",
    "    \n",
    "    \n",
    "    def _get_criterion(self, config):\n",
    "        \"\"\"No need explaintion. \n",
    "        \"\"\"\n",
    "        return CELossWithAuxHead()\n",
    "    \n",
    "    \n",
    "    def load_weights(self, path):\n",
    "        \"\"\"Load pre-trained weights.\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        \n",
    "    def set_arc(self, arcs):\n",
    "        \"\"\"Set architectures. Must do this before calling the forward method.\n",
    "        \n",
    "        Args:\n",
    "            arcs: tuple of two lists that contain integers represents the \n",
    "                architecture of a normal cell and a reduce cell.\n",
    "        \"\"\"\n",
    "        self.arcs = arcs\n",
    "        \n",
    "        \n",
    "    def loss_batch(self, loss_func, outputs, target, norm=None, optimizer=None):\n",
    "        \"\"\"Compute loss and update model weights on a batch of data.\n",
    "\n",
    "        Args:\n",
    "            outputs: [batch_size, class_num]\n",
    "            target: [batch_size]\n",
    "        \"\"\"\n",
    "        loss = loss_func(outputs, target)\n",
    "        if norm is not None:\n",
    "            loss /= norm\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            with torch.set_grad_enabled(True):\n",
    "                loss.backward() # compute gradients\n",
    "                optimizer.step() # update weights\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "        return loss.item()\n",
    "    \n",
    "    \n",
    "    def train_epoch(self, model, dataset, criterion, optimizer, epoch):\n",
    "        \"\"\"Train the model for one single epoch.\n",
    "        \"\"\"\n",
    "        model.train() # set the model to train mode\n",
    "        prog = Progbar(target=len(dataset)) # progress bar for visualization\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(dataset):\n",
    "            if self.arcs is None:\n",
    "                raise Exception(\"Did you forget to set model arcs?\")\n",
    "            outputs = model(images, self.arcs)\n",
    "            \n",
    "            # compute loss and update model parameters on a batch of data\n",
    "            batch_loss = self.loss_batch(criterion, outputs, labels, optimizer=optimizer)\n",
    "            train_loss += batch_loss\n",
    "            prog.update(i + 1, [(\"batch loss\", batch_loss)])\n",
    "            \n",
    "            if self.writer is not None: # write summary to tensorboard\n",
    "                self.writer.add_scalar('batch_loss', batch_loss, epoch*len(dataset) + i + 1)\n",
    "            \n",
    "                # draw the diagram for the first batch of data\n",
    "                # if i == 0 and epoch == 0:\n",
    "                #     self.writer.add_graph(self.model, (en_input, en_mask, de_input, de_mask), verbose=False)\n",
    "\n",
    "        # compute the average loss\n",
    "        epoch_loss = train_loss / len(dataset)\n",
    "        return epoch_loss\n",
    "    \n",
    "    \n",
    "    def evaluate(self, model, dataset, criterion):\n",
    "        \"\"\"Evaluate the model, return average loss and accuracy.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            eval_loss, eval_corrects = 0., 0.\n",
    "            for i, (images, labels) in enumerate(dataset):\n",
    "                if self.arcs is None:\n",
    "                    raise Exception(\"Did you forget to set model arcs?\")\n",
    "                outputs = model(images, self.arcs) # logits: [N, class_num]\n",
    "                \n",
    "                # compute loss and update model parameters on a batch of data\n",
    "                batch_loss = self.loss_batch(criterion, outputs, labels, optimizer=None)\n",
    "                eval_loss += batch_loss\n",
    "                \n",
    "                pred_labels = torch.argmax(ouputs, dim=-1)\n",
    "\n",
    "                assert pred_labels.shape == labels.shape, \"Predition output shape {} and actual labels shape {} does Not match.\".format(pred_labels.shape, labels.shape)\n",
    "                matching = (pred_labels == target)\n",
    "                eval_corrects += torch.sum(matching).double()\n",
    "\n",
    "            avg_loss = eval_loss / len(dataset)\n",
    "            avg_acc  = eval_corrects / len(dataset)\n",
    "\n",
    "        return avg_loss, avg_acc\n",
    "    \n",
    "    \n",
    "    def fit(self, train_set, development_set, samples=None):\n",
    "        \"\"\"Model training.\n",
    "        \"\"\"\n",
    "        num_epochs = self.config.num_epochs\n",
    "        best_acc = 0.\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.logger.info('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            # print('-' * 10)\n",
    "            # train\n",
    "            train_loss = self.train_epoch(self.model, train_set, self.criterion, self.optimizer, epoch)\n",
    "            self.logger.info(\"Traing Loss: {}\".format(train_loss))\n",
    "\n",
    "            # eval\n",
    "            eval_loss, eval_acc = self.evaluate(self.model, development_set, self.criterion)\n",
    "            self.logger.info(\"Evaluation:\")\n",
    "            self.logger.info(\"- loss: {}\".format(eval_loss))\n",
    "            self.logger.info(\"- acc: {}\".format(eval_acc))\n",
    "\n",
    "            # print samples\n",
    "            decode_seq = self._greedy_decode(self.model, samples[0], samples[1], \n",
    "                    self.config.max_steps, self.config.start_symbol)\n",
    "            for i, (s, r) in enumerate(zip(samples[0], decode_seq)):\n",
    "                print(\"# \", i+1)\n",
    "                print('- samples: {}'.format(s.tolist()))\n",
    "                print('- results: {}'.format(r.tolist()))\n",
    "\n",
    "            # monitor loss and accuracy\n",
    "            if self.writer is not None:\n",
    "                self.writer.add_scalar('epoch_loss', train_loss, epoch)\n",
    "                self.writer.add_scalar('eval_loss', eval_loss, epoch)\n",
    "                self.writer.add_scalar('eval_acc', eval_acc, epoch)\n",
    "\n",
    "            # save the model\n",
    "            if eval_acc >= best_acc:\n",
    "                best_acc = eval_acc\n",
    "                self.logger.info(\"New best score!\")\n",
    "                torch.save(self.model.state_dict(), self.config.dir_model + \"model.pickle\")\n",
    "                self.logger.info(\"model is saved at: {}\".format(self.config.dir_model))\n",
    "\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        \"\"\"Prediction.\n",
    "        \n",
    "        Return:\n",
    "            outputs: logits [N, class_num]\n",
    "            pred_labels: [N]\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            if self.arcs is None:\n",
    "                raise Exception(\"Did you forget to set model arcs?\")\n",
    "            outputs = self.model(inputs, self.arcs)    # outputs: [N, class_num]\n",
    "            pred_labels = torch.argmax(outputs, dim=-1) # [N]\n",
    "            \n",
    "        return outputs, pred_labels\n",
    "    \n",
    "    \n",
    "    def test(self, dataset):\n",
    "        \"\"\"Test the model and print out a report.\n",
    "        \"\"\"\n",
    "        self.model.eval() \n",
    "        with torch.no_grad():\n",
    "            total_samples, corrects = 0, 0\n",
    "            pred_class, label_class = [], []\n",
    "            for images, labels in dataset:\n",
    "                _, pred_labels = self.predict(images)\n",
    "\n",
    "                corrects += torch.sum(labels == pred_labels).double()\n",
    "                total_samples += labels.shape[0]\n",
    "                \n",
    "                for p, l in zip(pred_labels, labels):\n",
    "                    pred_class.append(p)\n",
    "                    label_class.append(l)\n",
    " \n",
    "            accuracy = corrects / total_samples\n",
    "            self.logger.info('\\n')\n",
    "            self.logger.info('Accuracy: {:.3}\\n\\n'.format(accuracy))\n",
    "            self.logger.info(classification_report(label_class, pred_class))\n",
    "        \n",
    "        return label_class, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3026)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.ones([10, 10], dtype=torch.float32)\n",
    "target = torch.ones([10], dtype=torch.int64)\n",
    "aux_logits = torch.zeros([10, 10], dtype=torch.int64)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, target)\n",
    "print(loss)\n",
    "print(loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
